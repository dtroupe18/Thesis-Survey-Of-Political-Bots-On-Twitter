{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import math\n",
    "import nltk\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "import re\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_master_political_words():\n",
    "    political_words = ['maga','trump', 'conservative','christian','ðŸ‡ºðŸ‡¸','country','american','patriot','nra',\n",
    "                        '2a','america','resist','president','politics','theresistance','veteran','kag','news',\n",
    "                        'liberal','political','usa','vet','jesus','military','freedom','resistance','constitution',\n",
    "                        'trump2020','army','potus','qanon','trumptrain','draintheswamp','independent','democrat',\n",
    "                        'buildthewall','americafirst','republican','government','justice','history','prolife',\n",
    "                        'law','navy','donald','progressive','liberty','israel','usaf','marine','constitutional','vets',\n",
    "                        'libertarian','liberals','amendment','gop','bluewave','usmc','veterans','nation','backtheblue',\n",
    "                        'atheist','patriots','q','vietnam','police','states','democracy','realdonaldtrump','bluewave2018',\n",
    "                        'impeachtrump','bluelivesmatter','pro-life','constitutionalist','feminist','u.s.','notmypresident',\n",
    "                        'genflynn','kag2020','politically','obama','flag','magaðŸ‡ºðŸ‡¸','brexit','americans','national',\n",
    "                        'patriotic','voted','voter']\n",
    "    return political_words\n",
    "\n",
    "common_political_words = [\n",
    "    'potus',\n",
    "    'qanon',\n",
    "    'trumptrain',\n",
    "    'draintheswamp',\n",
    "    'democrat',\n",
    "    'buildthewall',\n",
    "    'americafirst',\n",
    "    'republican',\n",
    "    'prolife',\n",
    "    'maga',\n",
    "    'trump',\n",
    "    'conservative',\n",
    "    'patriot',\n",
    "    'nra',\n",
    "    '2a',\n",
    "    'resist',\n",
    "    'politics',\n",
    "    'theresistance',\n",
    "    'liberal',\n",
    "    'resistance',\n",
    "    'constitution',\n",
    "    'trump2020',\n",
    "    'kag'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_master_id_data(file_name, col_name=None):\n",
    "    sub_directories = '/Data/Master-Data/'\n",
    "    base_path = os.getcwd()\n",
    "    full_path = base_path + sub_directories + file_name\n",
    "    \n",
    "    if col_name is not None:\n",
    "        return pd.read_csv(full_path, usecols=[col_name])\n",
    "    \n",
    "    # print('Full Path: ', full_path)\n",
    "    return pd.read_csv(full_path, header=0)\n",
    "\n",
    "def clean_text(text):\n",
    "    tok = WordPunctTokenizer()\n",
    "    stop_words = nltk.corpus.stopwords.words('english')\n",
    "    pat1 = r'@[A-Za-z0-9]+'\n",
    "    pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "    combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "    stripped = re.sub(combined_pat, '', text)\n",
    "    \n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "        \n",
    "    return (\" \".join(words)).strip()\n",
    "\n",
    "\n",
    "def clean_descriptions(df):\n",
    "    # df.isnull().sum() \n",
    "    # About 40k users do not have a description\n",
    "    df.dropna(subset=['user_description'], how='all', inplace = True)\n",
    "    df['cleaned_description'] = df['user_description'].apply(lambda x: clean_text(x))\n",
    "    return df\n",
    "\n",
    "\n",
    "def find_n_most_common_words(df, col_name, n):\n",
    "    # Find the most common political words in User Descriptions\n",
    "    \n",
    "    # These characters will appear as their own word if not removed. This results in the hashtag\n",
    "    # being the most common word. These characters are removed from the results\n",
    "    my_stop_words = [',', 'â€™', '#', '.', '!', '@', '&', ':', '|', '(', ')', \n",
    "                 '\\'s', ';', '-', 'n\\'t', '%', '...', '\\'m', 'http', 'https', 'de']\n",
    "\n",
    "    # Read in the profile descriptions\n",
    "    description_series = df[col_name]\n",
    "    top_n = n\n",
    "\n",
    "    # Lowercase everything in the description so words of different cases are counted the same\n",
    "    # Ex: Maga and MAGA\n",
    "    #\n",
    "    lowercase_descriptions = description_series.str.lower().str.cat(sep=' ')\n",
    "    words = nltk.tokenize.word_tokenize(lowercase_descriptions)\n",
    "    word_dist = nltk.FreqDist(words)\n",
    "\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "    # Include the stop words I created\n",
    "    stopwords.extend(my_stop_words)\n",
    "\n",
    "    # Remove stopwords from the results\n",
    "    words_except_stop_dist = nltk.FreqDist(w for w in words if w not in stopwords)\n",
    "\n",
    "    results = pd.DataFrame(words_except_stop_dist.most_common(top_n), columns=['Word', 'Frequency']) #.set_index('Word')\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "def calculate_political_word_counts(df):\n",
    "    # Calculate the number of political words in each user's description\n",
    "    \n",
    "    political_words = get_master_political_words()\n",
    "    \n",
    "    political_word_counts = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        description_words = row['cleaned_description'].split()\n",
    "        \n",
    "        political_words_left = list(set(political_words) - set(description_words))\n",
    "        political_word_count = len(political_words) - len(political_words_left)\n",
    "        political_word_counts.append(political_word_count)\n",
    "        \n",
    "    df['political_word_count'] = political_word_counts\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def show_statistics(col_name, text_for_print, df):\n",
    "    \n",
    "    # Calculate the average \n",
    "    average = sum(df[col_name]) / len(df)\n",
    "    print(col_name + ' average: ' + str(round(average, 2)))\n",
    "\n",
    "    # Calculate standard deviation\n",
    "    std = df[col_name].std()\n",
    "    print(text_for_print + ' standard deviation ' + str(std))\n",
    "\n",
    "    # Calculate the range \n",
    "    max = df[col_name].max()\n",
    "    min = df[col_name].min()\n",
    "    print(text_for_print, \" ranges from \", str(min), \" - \", str(max))\n",
    "    \n",
    "    # Calculate the number of rows with zero\n",
    "    zero_df = df[df[col_name] == 0]\n",
    "    print(text_for_print, \" has \", str(len(zero_df)), ' rows with zero as their value')\n",
    "    \n",
    "\n",
    "def get_political_users(df, min_val, equal=False):\n",
    "    if equal:\n",
    "        df = df[df.political_word_count >= min_val]\n",
    "    else:\n",
    "        df = df[df.political_word_count > min_val]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_top_5_percent_cap_scores(df):\n",
    "    n = int(0.05 * len(df))\n",
    "    print('n: ', n)\n",
    "    top_five = df['cap'].nlargest(n)\n",
    "    return top_five\n",
    "\n",
    "\n",
    "def get_top_5_bot_scores(df):\n",
    "    n = int(0.05 * len(df))\n",
    "    print('n: ', n)\n",
    "    top_five = df['bot_score'].nlargest(n)\n",
    "    return top_five\n",
    "\n",
    "\n",
    "def get_min_bot_cap_score(df):\n",
    "    top = get_top_5_percent_cap_scores(df)\n",
    "    lowest = list(top)[-1]\n",
    "    print('lowest: ', lowest)\n",
    "    return lowest\n",
    "\n",
    "\n",
    "def get_min_bot_score(df):\n",
    "    top = get_top_5_bot_scores(df)\n",
    "    lowest = list(top)[-1]\n",
    "    print('lowest: ', lowest)\n",
    "    return lowest\n",
    "\n",
    "\n",
    "def get_top_5_cap_scores_df(df):\n",
    "    lowest = get_min_bot_cap_score(df)\n",
    "    return df[df.cap > lowest]\n",
    "    \n",
    "    \n",
    "def get_top_5_bot_scores_df(df):\n",
    "    lowest = get_min_bot_cap_score(df)\n",
    "    return df[df.bot_score >= lowest]\n",
    "\n",
    "\n",
    "def print_to_text_file(file_name, data, with_new_line=True):\n",
    "    file_name += \".txt\"\n",
    "    with open(file_name, \"w\") as text_file:\n",
    "        for x in data:\n",
    "            if with_new_line:\n",
    "                text_file.write(\"{}\\n\".format(x))\n",
    "            else:\n",
    "                text_file.write(\"\\'{}\\',\\n\".format(x))\n",
    "        \n",
    "        text_file.close()\n",
    "        print('Finished creating ', file_name)\n",
    "        return\n",
    "    \n",
    "\n",
    "def save_to_pickle(file_name, data):\n",
    "    file_name += '.pkl'\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "\n",
    "def open_from_pickle(file_name):\n",
    "    file_name += '.pkl'\n",
    "    with open(file_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        return data\n",
    "\n",
    "def save_df_to_csv(df, file_name):\n",
    "    file_name += '.csv'\n",
    "    df.to_csv(file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(241300, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = load_master_id_data('MasterIDs.csv') \n",
    "df = load_master_id_data('MasterIDs-2.csv')\n",
    "df.shape # total number of accounts scraped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap average: 0.06\n",
      "cap score standard deviation 0.1322926375380892\n",
      "cap score  ranges from  0.001556878998692371  -  0.9670261466915276\n",
      "cap score  has  0  rows with zero as their value\n"
     ]
    }
   ],
   "source": [
    "show_statistics('cap', 'cap score', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_descriptions(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most_common_description_words = find_n_most_common_words(df, 'user_description', 500)\n",
    "# word_list = most_common_description_words['Word'].tolist()\n",
    "# print_to_text_file(\"most_common_words_as_list\", word_list, with_new_line=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_political_word_counts(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "political_word_count average: 1.42\n",
      "political word count standard deviation 1.7943026474578256\n",
      "political word count  ranges from  0  -  13\n",
      "political word count  has  84722  rows with zero as their value\n"
     ]
    }
   ],
   "source": [
    "show_statistics('political_word_count', 'political word count', df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# political_df = get_political_users(df)\n",
    "political_df = get_political_users(df, 1, equal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(106825, 30)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "political_df.shape # First number is the total number of accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap average: 0.05\n",
      "cap score standard deviation 0.09838781503735348\n",
      "cap score  ranges from  0.001556878998692371  -  0.9670261466915276\n",
      "cap score  has  0  rows with zero as their value\n"
     ]
    }
   ],
   "source": [
    "show_statistics('cap', 'cap score', political_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1222\n",
      "134\n",
      "103437\n"
     ]
    }
   ],
   "source": [
    "political_bots = political_df[political_df.cap > 0.53]\n",
    "def_political_bots = political_df[political_df.cap >= 0.8]\n",
    "political_humans = political_df[political_df.cap < 0.3]\n",
    "\n",
    "print(len(political_bots))\n",
    "print(len(def_political_bots))\n",
    "print(len(political_humans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_csv(political_humans, 'political_human_profiles(1-word)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_bot_ids = political_bots.user_id.tolist()\n",
    "save_to_pickle('political_bot_ids(1-word)', political_bot_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_to_csv(political_bots, 'political_bot_profiles(1-word)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap average: 0.66\n",
      "cap score standard deviation 0.10604601853488954\n",
      "cap score  ranges from  0.5319634089641295  -  0.9670261466915276\n",
      "cap score  has  0  rows with zero as their value\n"
     ]
    }
   ],
   "source": [
    "show_statistics('cap', 'cap score', political_bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap average: 0.87\n",
      "cap score standard deviation 0.045168078210361264\n",
      "cap score  ranges from  0.8055519629117155  -  0.9670261466915276\n",
      "cap score  has  0  rows with zero as their value\n"
     ]
    }
   ],
   "source": [
    "show_statistics('cap', 'cap score', def_political_bots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def_bot_usernames = def_political_bots.user_screen_name.tolist()\n",
    "# print_to_text_file(\"def_bot_usernames\", def_bot_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_most_common_political_words(df):\n",
    "    # Read in the descriptions\n",
    "    description_series = df['cleaned_description']\n",
    "    top_n = 50\n",
    "\n",
    "    # Lowercase everything in the description so words of different cases are counted the same\n",
    "    # Ex: Maga and MAGA\n",
    "    #\n",
    "    lowercased = description_series.str.lower().str.cat(sep=' ')\n",
    "    words = nltk.tokenize.word_tokenize(lowercased)\n",
    "    word_dist = nltk.FreqDist(words)\n",
    "\n",
    "    return pd.DataFrame(word_dist.most_common(top_n), columns=['Word', 'Frequency'])#.set_index('Word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Word  Frequency\n",
      "0            maga        426\n",
      "1           trump        343\n",
      "2    conservative        141\n",
      "3            news        134\n",
      "4             kag        118\n",
      "5            love        111\n",
      "6             god        108\n",
      "7             nra        105\n",
      "8       christian        102\n",
      "9         america         97\n",
      "10          proud         92\n",
      "11        patriot         90\n",
      "12       military         82\n",
      "13       american         74\n",
      "14        country         72\n",
      "15      president         67\n",
      "16         family         66\n",
      "17      supporter         63\n",
      "18         follow         60\n",
      "19       politics         57\n",
      "20            pro         55\n",
      "21  draintheswamp         55\n",
      "22   americafirst         54\n",
      "23        support         54\n",
      "24     trumptrain         53\n",
      "25           life         53\n",
      "26   buildthewall         51\n",
      "27        prolife         51\n",
      "28             fb         48\n",
      "29        married         46\n",
      "30            vet         44\n",
      "31        veteran         42\n",
      "32             us         41\n",
      "33            usa         41\n",
      "34          potus         40\n",
      "35    backtheblue         39\n",
      "36     deplorable         39\n",
      "37           army         38\n",
      "38        retired         38\n",
      "39   constitution         38\n",
      "40          great         38\n",
      "41         israel         37\n",
      "42           wife         36\n",
      "43         donald         36\n",
      "44           vets         36\n",
      "45       veterans         34\n",
      "46           back         33\n",
      "47         father         32\n",
      "48        husband         31\n",
      "49          lists         31\n"
     ]
    }
   ],
   "source": [
    "most_common = show_most_common_political_words(political_bots)\n",
    "print(most_common)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
